<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ESP32 é›™å‘èªéŸ³ + MJPEG ä¸²æµ</title>
  <style>
    body { font-family: system-ui, sans-serif; margin: 0; background: #111; color: #fff; text-align: center; padding: 20px; }
    h2 { margin-bottom: 16px; }
    img { width: 100%; max-width: 480px; border-radius: 12px; background: #000; }
    .btn { font-size: 16px; padding: 10px 20px; margin: 10px 5px; border-radius: 8px; border: none; cursor: pointer; }
    .btn:hover { background: #333; }
  </style>
</head>
<body>
  <h2>ESP32 é›™å‘èªéŸ³ + MJPEG ä¸²æµ</h2>
  <img id="cam" src="" alt="ESP32 Camera Stream" />
  <div>
    <button class="btn" onclick="startCam()">ğŸ“· å•Ÿå‹•é¡é ­</button>
    <button class="btn" onclick="stopCam()">ğŸ›‘ åœæ­¢é¡é ­</button>
    <button class="btn" onclick="startMic()">ğŸ™ï¸ é–‹å§‹èªéŸ³</button>
    <button class="btn" onclick="stopMic()">ğŸ”‡ åœæ­¢èªéŸ³</button>
  </div>

<script>
let ws, audioCtx, micNode, srcNode, running = false, imageBuffer = [];
let camOn = false;
const SR = 16000;

async function ensureCtx() {
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SR });
    if (audioCtx.state === 'suspended') await audioCtx.resume();

    const blob = new Blob([`
      class PCMProcessor extends AudioWorkletProcessor {
        constructor() {
          super(); this.acc = []; this.target = 1024;
        }
        process(inputs) {
          const ch0 = inputs[0]?.[0]; if (!ch0) return true;
          this.acc.push(...ch0);
          while (this.acc.length >= this.target) {
            const s = this.acc.splice(0, this.target);
            const pcm = new Int16Array(s.length);
            for (let i = 0; i < s.length; i++) {
              let v = Math.max(-1, Math.min(1, s[i]));
              pcm[i] = v < 0 ? v * 0x8000 : v * 0x7FFF;
            }
            this.port.postMessage(pcm.buffer, [pcm.buffer]);
          }
          return true;
        }
      }
      registerProcessor('pcm-processor', PCMProcessor);
    `], { type: 'application/javascript' });
    const url = URL.createObjectURL(blob);
    await audioCtx.audioWorklet.addModule(url);
  }
}

async function startMic() {
  if (!ws || ws.readyState !== WebSocket.OPEN) return;
  if (running) return;
  running = true;

  await ensureCtx();
  await audioCtx.resume();

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  srcNode = audioCtx.createMediaStreamSource(stream);
  micNode = new AudioWorkletNode(audioCtx, "pcm-processor", {
    numberOfInputs: 1,
    numberOfOutputs: 1,
    outputChannelCount: [1]
  });
  const sink = audioCtx.createGain();
  sink.gain.value = 0.0;
  micNode.connect(sink).connect(audioCtx.destination);
  srcNode.connect(micNode);

  micNode.port.onmessage = (ev) => {
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.send(ev.data);
    }
  };

  ws.send("START_MIC");
  console.log("ğŸ™ï¸ èªéŸ³ä¸Šå‚³é–‹å§‹");
}

function stopMic() {
  running = false;
  try { srcNode?.disconnect(); } catch (_) {}
  try { micNode?.disconnect(); } catch (_) {}
  ws?.send("STOP_MIC");
  console.log("ğŸ›‘ èªéŸ³åœæ­¢");
}

function startCam() {
  if (!ws || ws.readyState !== WebSocket.OPEN) return;
  camOn = true;
  ws.send("START_CAM");
  console.log("ğŸ“· å•Ÿå‹•ç›¸æ©Ÿä¸²æµ");
}

function stopCam() {
  camOn = false;
  ws?.send("STOP_CAM");
  console.log("ğŸ›‘ é—œé–‰ç›¸æ©Ÿä¸²æµ");
}

function initWS() {
  ws = new WebSocket("wss://esp32-server-st33.onrender.com/toPhone");
  ws.binaryType = "arraybuffer";

  ws.onopen = () => {
    console.log("âœ… WebSocket å·²é€£ç·š");
  };

  ws.onmessage = async (event) => {
    let ab = event.data;
    if (!(ab instanceof ArrayBuffer)) {
      if (ab?.arrayBuffer) ab = await ab.arrayBuffer();
      else return;
    }

    const u8 = new Uint8Array(ab);

    // JPEG åˆæˆ
    if (u8[0] === 0xFF && u8[1] === 0xD8) {
      imageBuffer = [u8];
      return;
    }

    if (imageBuffer.length > 0) {
      imageBuffer.push(u8);
      if (u8[u8.length - 2] === 0xFF && u8[u8.length - 1] === 0xD9) {
        const total = imageBuffer.reduce((sum, part) => sum + part.length, 0);
        const full = new Uint8Array(total);
        let offset = 0;
        for (const part of imageBuffer) full.set(part, offset), offset += part.length;
        document.getElementById("cam").src = URL.createObjectURL(new Blob([full], { type: "image/jpeg" }));
        imageBuffer = [];
      }
      return;
    }

    // æ’­æ”¾éŸ³è¨Š
    const pcm16 = new Int16Array(ab);
    const f32 = new Float32Array(pcm16.length);
    for (let i = 0; i < pcm16.length; i++) f32[i] = pcm16[i] / 32768.0;

    const buf = audioCtx.createBuffer(1, f32.length, SR);
    buf.copyToChannel(f32, 0);

    const src = audioCtx.createBufferSource();
    src.buffer = buf;
    src.connect(audioCtx.destination);
    src.start();
  };

  ws.onclose = () => {
    console.warn("ğŸ”Œ WebSocket é—œé–‰ï¼Œå°‡è‡ªå‹•é‡é€£");
    setTimeout(initWS, 3000);
  };
}

initWS();
</script>
</body>
</html>
