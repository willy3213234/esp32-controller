<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ESP32 é›™å‘èªéŸ³ + MJPEG ä¸²æµ</title>
  <style>
    body { font-family: system-ui, sans-serif; margin: 0; background: #111; color: #fff; text-align: center; padding: 20px; }
    h2 { margin-bottom: 16px; }
    img { width: 100%; max-width: 480px; border-radius: 12px; background: #000; }
    .btn { font-size: 16px; padding: 10px 20px; margin: 10px 5px; border-radius: 8px; border: none; cursor: pointer; }
    .btn:hover { background: #333; }
  </style>
</head>
<body>
  <h2>ESP32 é›™å‘èªéŸ³ + MJPEG ä¸²æµ</h2>
  <img id="cam" src="" alt="ESP32 Camera Stream" />
  <div>
    <button class="btn" onclick="startCam()">ğŸ“· å•Ÿå‹•é¡é ­</button>
    <button class="btn" onclick="stopCam()">ğŸ›‘ åœæ­¢é¡é ­</button>
    <button class="btn" onclick="startMic()">ğŸ™ï¸ é–‹å§‹èªéŸ³</button>
    <button class="btn" onclick="stopMic()">ğŸ”‡ åœæ­¢èªéŸ³</button>
  </div>

<script>
let ws, audioCtx, micNode, srcNode, running = false, imageBuffer = [];
let camOn = false;
const SR = 16000;

  ws = new WebSocket("wss://esp32-server-st33.onrender.com/toPhone");
  ws.binaryType = "arraybuffer";

  ws.onopen = () => {
  console.log("âœ… WebSocket toPhone connected");
  ws.send("START_MIC");  // åŠ é€™ä¸€è¡Œè§£æ±ºå•é¡Œ
};

async function ensureCtx() {
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SR });
    if (audioCtx.state === 'suspended') await audioCtx.resume();

    const blob = new Blob([`
      class PCMProcessor extends AudioWorkletProcessor {
        constructor() {
          super(); this.acc = []; this.target = 1024;
        }
        process(inputs) {
          const ch0 = inputs[0]?.[0]; if (!ch0) return true;
          this.acc.push(...ch0);
          while (this.acc.length >= this.target) {
            const s = this.acc.splice(0, this.target);
            const pcm = new Int16Array(s.length);
            for (let i = 0; i < s.length; i++) {
              let v = Math.max(-1, Math.min(1, s[i]));
              pcm[i] = v < 0 ? v * 0x8000 : v * 0x7FFF;
            }
            this.port.postMessage(pcm.buffer, [pcm.buffer]);
          }
          return true;
        }
      }
      registerProcessor('pcm-processor', PCMProcessor);
    `], { type: 'application/javascript' });
    const url = URL.createObjectURL(blob);
    await audioCtx.audioWorklet.addModule(url);
  }
}

async function startMic() {
  if (running) return;
  running = true;
  await ensureCtx();
  await audioCtx.resume();



ws.onmessage = async (event) => {
  let ab = event.data;
  if (!(ab instanceof ArrayBuffer)) {
    if (ab?.arrayBuffer) ab = await ab.arrayBuffer();
    else return;
  }

  const u8 = new Uint8Array(ab);

  // ğŸ“¸ è‹¥ç‚º JPEG é–‹é ­ï¼Œæ¸…ç©ºæš«å­˜ä¸¦é–‹å§‹æ”¶é›†
  if (u8[0] === 0xFF && u8[1] === 0xD8) {
    imageBuffer = [u8];
    return;
  }

  // ğŸ“¸ è‹¥æ­£åœ¨æ”¶é›†åœ–åƒ
  if (imageBuffer.length > 0) {
    imageBuffer.push(u8);

    // ğŸ§ª å˜—è©¦åˆ¤æ–·çµå°¾ï¼ˆJPEG çµå°¾ç‚º FF D9ï¼‰
    if (u8[u8.length - 2] === 0xFF && u8[u8.length - 1] === 0xD9) {
      const full = new Uint8Array(imageBuffer.reduce((sum, arr) => sum + arr.length, 0));
      let offset = 0;
      for (const part of imageBuffer) {
        full.set(part, offset);
        offset += part.length;
      }
      const blob = new Blob([full], { type: "image/jpeg" });
      document.getElementById("cam").src = URL.createObjectURL(blob);
      imageBuffer = [];
      console.log("ğŸ–¼ï¸ çµ„è£æˆåŠŸä¸¦é¡¯ç¤ºå¿«ç…§", full.length, "bytes");
    }
    return;
  }

  if (!ab || ab.byteLength < 2) {
    console.warn("âš ï¸ æ”¶åˆ°è³‡æ–™é•·åº¦éçŸ­");
    return;
  }

  const pcm16 = new Int16Array(ab);
  console.log("ğŸ“Š è§£æç‚º Int16Array:", pcm16);

  const f32 = new Float32Array(pcm16.length);
  for (let i = 0; i < pcm16.length; i++) f32[i] = pcm16[i] / 32768.0;

  const buf = audioCtx.createBuffer(1, f32.length, SR);
  buf.copyToChannel(f32, 0);

  const src = audioCtx.createBufferSource();
  src.buffer = buf;
  src.connect(audioCtx.destination);
  src.start();
  console.log("ğŸ”Š æ’­æ”¾ä¸­ï¼Œæ¨£æœ¬æ•¸:", f32.length);
};


  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  srcNode = audioCtx.createMediaStreamSource(stream);
  micNode = new AudioWorkletNode(audioCtx, "pcm-processor", {
    numberOfInputs: 1,
    numberOfOutputs: 1,
    outputChannelCount: [1]
  });
  const sink = audioCtx.createGain();
  sink.gain.value = 0.0;
  micNode.connect(sink).connect(audioCtx.destination);
  srcNode.connect(micNode);

  micNode.port.onmessage = (ev) => {
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.send(ev.data);
    }
  };
}

function stopMic() {
  running = false;
  try { srcNode?.disconnect(); } catch (_) {}
  try { micNode?.disconnect(); } catch (_) {}
  ws?.send("STOP_MIC");
  console.log("ğŸ›‘ èªéŸ³åœæ­¢");
}

function startCam() {
  if (!ws || ws.readyState !== WebSocket.OPEN) return;
  camOn = true;
  ws.send("START_CAM");
  console.log("ğŸ“· å•Ÿå‹•ç›¸æ©Ÿä¸²æµ");
}

function stopCam() {
  camOn = false;
  ws?.send("STOP_CAM");
  console.log("ğŸ›‘ é—œé–‰ç›¸æ©Ÿä¸²æµ");
}

</script>
</body>
</html>
