<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ESP32 é ç«¯æ§åˆ¶é¢æ¿</title>
  <style>
    body { font-family: system-ui, sans-serif; background: #111; color: #fff; padding: 20px; display: flex; gap: 40px; flex-wrap: wrap; }
    section { flex: 1 1 400px; background: #222; border-radius: 16px; padding: 20px; }
    h2 { margin-top: 0; }
    img, video, canvas { width: 100%; max-width: 480px; background: #000; border-radius: 12px; display: block; margin: 10px auto; }
    button { margin: 5px; padding: 10px 20px; font-size: 16px; border-radius: 8px; cursor: pointer; }
  </style>
</head>
<body>

<!-- ğŸ™ï¸ğŸ¥ ESP32-S3ï¼šé›™å‘èªéŸ³ + ç›¸æ©Ÿä¸²æµ -->
<section>
  <h2>ESP32-S3 ğŸ™ï¸ é›™å‘èªéŸ³ + ğŸ“¸ ç›¸æ©Ÿä¸²æµ</h2>
  <img id="cam" alt="Camera Stream" />
  <div>
    <button onclick="startCam()">ğŸ“· å•Ÿå‹•é¡é ­</button>
    <button onclick="stopCam()">ğŸ›‘ åœæ­¢é¡é ­</button>
    <button onclick="startMic()">ğŸ™ï¸ é–‹å§‹èªéŸ³</button>
    <button onclick="stopMic()">ğŸ”‡ åœæ­¢èªéŸ³</button>
  </div>
</section>

<!-- ğŸ“±ğŸ“¤ æ‰‹æ©Ÿå½±åƒ âœ ESP32-LCD é¡¯ç¤º -->
<section>
  <h2>ğŸ“± æ‰‹æ©Ÿå½±åƒ âœ ğŸ–¥ï¸ ESP32-LCD é¡¯ç¤º</h2>
  <video id="v" playsinline muted></video>
  <canvas id="c" style="display:none"></canvas>
  <div>
    <button id="startLcd">é–‹å§‹å‚³é€</button>
  </div>
</section>

<script type="module">

    (function () {
  const logBox = document.createElement('div');
  logBox.style.cssText = `
    position:fixed;bottom:0;left:0;width:100%;max-height:40%;
    overflow:auto;background:rgba(0,0,0,0.7);color:#0f0;
    font:12px/1.4 monospace;padding:6px;white-space:pre-wrap;z-index:9999;
  `;
  document.body.appendChild(logBox);

  const origLog = console.log, origErr = console.error;
  function print(prefix, args) {
    const msg = [...args].map(x => typeof x === 'object' ? JSON.stringify(x) : x).join(' ');
    logBox.textContent += `${prefix} ${msg}\n`;
    logBox.scrollTop = logBox.scrollHeight;
  }
  console.log = (...args) => { origLog(...args); print('ğŸ“—', args); };
  console.error = (...args) => { origErr(...args); print('ğŸ“•', args); };
})();

  
(async () => {
  // ======================== ğŸ™ï¸ éŸ³è¨Š + ç›¸æ©Ÿ ========================
  const SR = 16000;
  let ws_audio, ws_video, micNode, srcNode, audioCtx;
  let camOn = false, running = false;
  let lastUrl = null;
  const camEl = document.getElementById("cam");

  function connectSockets() {
    ws_audio = new WebSocket("wss://esp32-server-st33.onrender.com/toPhone/audio");
    ws_audio.binaryType = "arraybuffer";
    ws_audio.onmessage = (event) => {
      const raw = new Uint8Array(event.data);
      if (raw[0] !== 0x02) return;
      const pcm16 = new Int16Array(raw.buffer, 1);
      const f32 = new Float32Array(pcm16.length);
      for (let i = 0; i < pcm16.length; i++) f32[i] = pcm16[i] / 32768.0;
      const buf = audioCtx.createBuffer(1, f32.length, SR);
      buf.copyToChannel(f32, 0);
      const src = audioCtx.createBufferSource();
      src.buffer = buf;
      src.connect(audioCtx.destination);
      src.start();
    };

    ws_video = new WebSocket("wss://esp32-server-st33.onrender.com/toPhone/video");
    ws_video.binaryType = "arraybuffer";
    ws_video.onmessage = (event) => {
      const raw = new Uint8Array(event.data);
      if (raw[0] !== 0x01) return;
      const blob = new Blob([raw.slice(1)], { type: "image/jpeg" });
      const url = URL.createObjectURL(blob);
      if (lastUrl) URL.revokeObjectURL(lastUrl);
      lastUrl = url;
      camEl.src = url;
    };
  }

  async function ensureAudioCtx() {
    if (audioCtx) return;
    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SR });
    const blob = new Blob([`
      class PCMProcessor extends AudioWorkletProcessor {
        constructor() { super(); this.buf = []; this.target = 1024; }
        process(inputs) {
          const input = inputs[0]?.[0];
          if (!input) return true;
          this.buf.push(...input);
          while (this.buf.length >= this.target) {
            const out = new Int16Array(this.target);
            for (let i = 0; i < this.target; i++) {
              let s = this.buf.shift();
              out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            this.port.postMessage(out.buffer, [out.buffer]);
          }
          return true;
        }
      }
      registerProcessor("pcm-processor", PCMProcessor);
    `], { type: "application/javascript" });
    const url = URL.createObjectURL(blob);
    await audioCtx.audioWorklet.addModule(url);
  }

  window.startMic = async () => {
    if (running) return;
    running = true;
    await ensureAudioCtx();
    await audioCtx.resume();
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    srcNode = audioCtx.createMediaStreamSource(stream);
    micNode = new AudioWorkletNode(audioCtx, "pcm-processor", { numberOfInputs: 1, numberOfOutputs: 1, outputChannelCount: [1] });
    micNode.port.onmessage = (ev) => {
      if (ws_audio?.readyState === 1) {
        const audioBuf = new Uint8Array(ev.data.byteLength + 1);
        audioBuf[0] = 0x02;
        audioBuf.set(new Uint8Array(ev.data), 1);
        ws_audio.send(audioBuf);
      }
    };
    const silent = audioCtx.createGain(); silent.gain.value = 0;
    micNode.connect(silent).connect(audioCtx.destination);
    srcNode.connect(micNode);
    ws_audio?.send("START_MIC");
  };

  window.stopMic = () => {
    running = false;
    try { srcNode?.disconnect(); } catch (_) {}
    try { micNode?.disconnect(); } catch (_) {}
    ws_audio?.send("STOP_MIC");
  };

  window.startCam = () => {
    camOn = true;
    if (ws_video?.readyState === 1) ws_video.send("START_CAM");
  };

  window.stopCam = () => {
    camOn = false;
    if (ws_video?.readyState === 1) ws_video.send("STOP_CAM");
  };

  connectSockets();


  // ======================== ğŸ“± æ‰‹æ©Ÿè¦–è¨Š â†’ LCD ========================
const LCD_W = 240, LCD_H = 240;
let ws_lcd, v = document.getElementById('v'), c = document.getElementById('c');
c.width = LCD_W; c.height = LCD_H;

async function sendFrame() {
  if (!ws_lcd || ws_lcd.readyState !== 1) return;

  const ctx = c.getContext('2d', { willReadFrequently:true });
  ctx.drawImage(v, 0, 0, LCD_W, LCD_H);

  const img = ctx.getImageData(0, 0, LCD_W, LCD_H);
  const total = img.width * img.height;
  const rgb565 = new Uint8Array(total * 2);

  // RGBA8888 â†’ RGB565
  for (let i = 0, j = 0; i < total; i++, j += 4) {
    const r = img.data[j] >> 3;       // 5 bits
    const g = img.data[j+1] >> 2;     // 6 bits
    const b = img.data[j+2] >> 3;     // 5 bits
    const rgb = (r << 11) | (g << 5) | b;
    rgb565[i*2]   = rgb >> 8;         // é«˜ä½å…ƒçµ„
    rgb565[i*2+1] = rgb & 0xFF;       // ä½ä½å…ƒçµ„
  }
  

if (ws_lcd && ws_lcd.readyState === 1) {
  console.log("ğŸ“¤ å‚³é€ä¸€å¼µ", rgb565.length, "bytes");
  ws_lcd.send(rgb565);
}
  requestAnimationFrame(sendFrame); // ğŸŸ¢ æ»¿é€Ÿè·‘
}

document.getElementById('startLcd').onclick = async () => {
  const stream = await navigator.mediaDevices.getUserMedia({ video:true });
  v.srcObject = stream;
  v.muted = true;             // ğŸŸ¢ ç¢ºä¿éœéŸ³ï¼ˆå…è¨±æ‰‹æ©Ÿè‡ªå‹•æ’­æ”¾ï¼‰
  v.playsInline = true;

  await v.play();              // ğŸŸ¢ å¼·åˆ¶ç­‰åˆ°æœ‰ç•«é¢

  ws_lcd = new WebSocket("wss://esp32-server-st33.onrender.com/toPhone/lcd");
  ws_lcd.binaryType = 'arraybuffer';

  ws_lcd.onopen = () => {
    console.log("ğŸ“¡ LCD WebSocket å·²é€£ç·šï¼Œé–‹å§‹å‚³ç•«é¢");
    sendFrame();
  };
};


})();
</script>
</body>
</html>
